{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating   timestamp  imdbId\n",
      "0       1       31     2.5  1260759144  112792\n",
      "1       7       31     3.0   851868750  112792\n",
      "2      31       31     4.0  1273541953  112792\n",
      "3      32       31     4.0   834828440  112792\n",
      "4      36       31     3.0   847057202  112792\n",
      "(100004, 5)\n",
      "Number of Unique Movies: 9066\n",
      "Number of Unique Users: 671\n"
     ]
    }
   ],
   "source": [
    "# path to the data directory\n",
    "data_path = '/mnt/DataSets/MovieLens/ml-latest-small'\n",
    "\n",
    "# read ratings and links into dataframes\n",
    "df_ratings = pd.read_csv(os.path.join(data_path,'ratings.csv'), sep=',')         \n",
    "df_links = pd.read_csv(os.path.join(data_path,'links.csv'), sep=',')\n",
    "\n",
    "# joining ratings with links to get ImdbId which is needed for comparison to the DL approach\n",
    "df_joined = pd.merge(df_ratings, df_links, on=['movieId'])\n",
    "df_joined = df_joined.drop(['tmdbId'], axis=1)\n",
    "\n",
    "# creating a bunch of dicts on the various item Ids\n",
    "# note that UserIds don't need to be indexed here because they are consecutive integers from 1 to 671\n",
    "#movie_to_imdb = {} # key:MovieId, val:ImdbId\n",
    "movie_to_idx = {}  # key:MovieId, val: idx\n",
    "idx_to_imdb = {}   # key:idx, val:ImdbId\n",
    "idx = 0\n",
    "for row in df_joined.itertuples():\n",
    "    if(row[2] not in movie_to_idx):\n",
    "        #movie_to_imdb[row[2]] = row[5]\n",
    "        movie_to_idx[row[2]] = idx\n",
    "        idx_to_imdb[idx] = row[5]\n",
    "        idx +=1   \n",
    "\n",
    "print (df_joined.head(5))\n",
    "print (df_joined.shape)\n",
    "\n",
    "num_movies = len(movie_to_idx)\n",
    "print(\"Number of Unique Movies:\",num_movies)\n",
    "num_users = df_joined.userId.unique().shape[0]\n",
    "print(\"Number of Unique Users:\",num_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Ratings Matrix: (671, 9066)\n",
      "Sparsity %:  1.6439141608663475\n"
     ]
    }
   ],
   "source": [
    "# get the sparse ratings matrix\n",
    "rating_matrix = np.zeros((num_users, num_movies))\n",
    "for row in df_joined.itertuples():\n",
    "    rating_matrix[row[1]-1, movie_to_idx[row[2]]] = row[3]\n",
    "\n",
    "print (\"Shape of Ratings Matrix:\",rating_matrix.shape)\n",
    "\n",
    "sparsity = float(len(rating_matrix.nonzero()[0]))\n",
    "sparsity /= (rating_matrix.shape[0] * rating_matrix.shape[1])\n",
    "sparsity *= 100\n",
    "print (\"Sparsity %: \",sparsity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating Matrix shape: (671, 9066)\n",
      "Sim Matrix shape: (9066, 9066)\n",
      "--- It took 1.2085046768188477 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# compute the cosine similarity between Items by default (can be used for users if passing rating_matrix.T)\n",
    "def cosine_sim(rating_matrix):\n",
    "    sim_matrix = rating_matrix.T.dot(rating_matrix)\n",
    "    norm_matrix = np.array([np.sqrt(np.diagonal(sim_matrix))])\n",
    "    sim_matrix = (sim_matrix/(norm_matrix*norm_matrix.T))\n",
    "    return sim_matrix\n",
    "\n",
    "start_time = time.time()\n",
    "item_sim_matrix = cosine_sim(rating_matrix)\n",
    "\n",
    "print(\"Rating Matrix shape:\",rating_matrix.shape)\n",
    "print(\"Sim Matrix shape:\", item_sim_matrix.shape)\n",
    "print(\"--- It took %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity threshold: 0.0517881350127\n",
      "Number of similarities: 9809734\n"
     ]
    }
   ],
   "source": [
    "# consider only similarities greater than a threshold\n",
    "sim_th = np.mean(item_sim_matrix)\n",
    "\n",
    "sim_list = []\n",
    "for i in range(0,num_movies-1):\n",
    "    for j in range(i+1,num_movies):\n",
    "        if(item_sim_matrix[i][j] > sim_th):\n",
    "            sim_list.append((idx_to_imdb[i],idx_to_imdb[j],item_sim_matrix[i][j])) \n",
    "\n",
    "print(\"Similarity threshold:\", sim_th)\n",
    "print(\"Number of similarities:\",len(sim_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# save to a gzipped csv file for inspection and later re-loading\n",
    "# avoiding pickle here because I'd like to be able to read the output as well as load it anywhere\n",
    "\n",
    "df_out = pd.DataFrame(sim_list, columns =['ItemId1','ItemId2','Sim'])\n",
    "\n",
    "df_out.to_csv(data_path + \"/item_sim_cosine.gz\", compression=\"gzip\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Evaluation**\n",
    "\n",
    "Single-Item recommendation evaluation by considering the last two ratings of each User: SecondToLast used as a seed to get recommendations; Last used to evaluate whether the User ended up watching/rating that item. Metric: Precision@5"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "%%bash\n",
    "\n",
    "# prep the seed and evaluation files - one time operation\n",
    "cd /mnt/DataSets/MovieLens/ml-latest-small\n",
    "\n",
    "cat ratings.csv | tail -n+2 | cut -d, -f1-2 | \\\n",
    "    perl -e '%h=(); while(<>){chomp; @f=split(/,/); $h{$f[0]} = $f[1];} foreach $k( keys %h){print \"$k,$h{$k}\\n\";}' | \\\n",
    "    sort -t, -k1g > lastItemPerUser.csv\n",
    "\n",
    "cat ratings.csv | tail -n+2 | cut -d, -f1-2 | \\\n",
    "    perl -e '%h=(); $pre=\"\"; while(<>){chomp; @f=split(/,/); $h{$f[0]} = $pre; $pre =$f[1];} foreach $k( keys %h){print \"$k,$h{$k},1.0\\n\";}' | \\\n",
    "    sort -t, -k1g > SecondToLastItemPerUser.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.          0.50157897  0.48288893  0.46210555  0.45734757  0.44842716\n",
      "  0.44495504  0.41988885  0.41948274  0.41781405  0.41302175]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Reco1</th>\n",
       "      <th>Reco2</th>\n",
       "      <th>Reco3</th>\n",
       "      <th>Reco4</th>\n",
       "      <th>Reco5</th>\n",
       "      <th>Reco6</th>\n",
       "      <th>Reco7</th>\n",
       "      <th>Reco8</th>\n",
       "      <th>Reco9</th>\n",
       "      <th>Reco10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2968</td>\n",
       "      <td>84827</td>\n",
       "      <td>101889</td>\n",
       "      <td>82348</td>\n",
       "      <td>83791</td>\n",
       "      <td>90728</td>\n",
       "      <td>84726</td>\n",
       "      <td>93870</td>\n",
       "      <td>101272</td>\n",
       "      <td>82340</td>\n",
       "      <td>94721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>661</td>\n",
       "      <td>116583</td>\n",
       "      <td>29583</td>\n",
       "      <td>57546</td>\n",
       "      <td>67992</td>\n",
       "      <td>32455</td>\n",
       "      <td>33563</td>\n",
       "      <td>32910</td>\n",
       "      <td>58331</td>\n",
       "      <td>59742</td>\n",
       "      <td>107688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>58559</td>\n",
       "      <td>371746</td>\n",
       "      <td>372784</td>\n",
       "      <td>1375666</td>\n",
       "      <td>499549</td>\n",
       "      <td>910970</td>\n",
       "      <td>167260</td>\n",
       "      <td>407887</td>\n",
       "      <td>416449</td>\n",
       "      <td>1345836</td>\n",
       "      <td>796366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3265</td>\n",
       "      <td>103905</td>\n",
       "      <td>120265</td>\n",
       "      <td>117786</td>\n",
       "      <td>75029</td>\n",
       "      <td>19422</td>\n",
       "      <td>92263</td>\n",
       "      <td>94138</td>\n",
       "      <td>84156</td>\n",
       "      <td>3799694</td>\n",
       "      <td>3065204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>41569</td>\n",
       "      <td>407304</td>\n",
       "      <td>258000</td>\n",
       "      <td>892782</td>\n",
       "      <td>1230414</td>\n",
       "      <td>338751</td>\n",
       "      <td>1058017</td>\n",
       "      <td>405159</td>\n",
       "      <td>978764</td>\n",
       "      <td>265086</td>\n",
       "      <td>411477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  UserId   Seed   Reco1   Reco2    Reco3    Reco4   Reco5    Reco6   Reco7  \\\n",
       "0      1   2968   84827  101889    82348    83791   90728    84726   93870   \n",
       "1      2    661  116583   29583    57546    67992   32455    33563   32910   \n",
       "2      3  58559  371746  372784  1375666   499549  910970   167260  407887   \n",
       "3      4   3265  103905  120265   117786    75029   19422    92263   94138   \n",
       "4      5  41569  407304  258000   892782  1230414  338751  1058017  405159   \n",
       "\n",
       "    Reco8    Reco9   Reco10  \n",
       "0  101272    82340    94721  \n",
       "1   58331    59742   107688  \n",
       "2  416449  1345836   796366  \n",
       "3   84156  3799694  3065204  \n",
       "4  978764   265086   411477  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 10   # number of most similar movies to display\n",
    "\n",
    "# read in the seed file\n",
    "df_seeds = pd.read_csv(os.path.join(data_path,'SecondToLastItemPerUser.csv'), sep=',', header = None, names=['UserId','ItemId'])\n",
    "df_seeds.head(5)\n",
    "\n",
    "# iterating over the dataframe rows and requesting 5 recos for each seed Item\n",
    "#for i in range(simDF.shape[0]):\n",
    "reco_list_all = []\n",
    "for row in df_seeds.itertuples(): # row[0] is the df index\n",
    "    movie_seed = row[2]\n",
    "    sorted_indx = np.argsort(item_sim_matrix[movie_to_idx[movie_seed],:])[::-1][:k+1]\n",
    "    #scores = np.sort(item_sim_matrix[movie_to_idx[movie_seed],:])[::-1][:k+1]\n",
    "    reco_list = []\n",
    "    reco_list.append(row[1])\n",
    "    reco_list.append(row[2])\n",
    "    for i in range(1,len(sorted_indx)):\n",
    "        reco_list.append(idx_to_imdb[sorted_indx[i]])\n",
    "    reco_list_all.append(reco_list)\n",
    "\n",
    "\n",
    "df_recos = pd.DataFrame(reco_list_all, dtype='str')\n",
    "df_recos.columns = ['UserId', 'Seed','Reco1', 'Reco2', 'Reco3', 'Reco4', 'Reco5', 'Reco6', 'Reco7', 'Reco8', 'Reco9', 'Reco10'] \n",
    "df_recos.head(5)\n",
    "#df_recos.to_csv(data_path + '/CF_cosine_ItemRecos.csv', index=False, header=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  UserId   Seed   Reco1   Reco2    Reco3    Reco4   Reco5    Reco6   Reco7  \\\n",
      "0      1   2968   84827  101889    82348    83791   90728    84726   93870   \n",
      "1      2    661  116583   29583    57546    67992   32455    33563   32910   \n",
      "2      3  58559  371746  372784  1375666   499549  910970   167260  407887   \n",
      "3      4   3265  103905  120265   117786    75029   19422    92263   94138   \n",
      "4      5  41569  407304  258000   892782  1230414  338751  1058017  405159   \n",
      "\n",
      "    Reco8    Reco9   Reco10  ItemId  \n",
      "0  101272    82340    94721    3671  \n",
      "1   58331    59742   107688     720  \n",
      "2  416449  1345836   796366   84236  \n",
      "3   84156  3799694  3065204    4006  \n",
      "4  978764   265086   411477   48385  \n",
      "Precision: 0.0\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv(os.path.join(data_path,'lastItemPerUser.csv'), sep=',', header = None, names=['UserId','ItemId'])\n",
    "\n",
    "df_eval = pd.merge(df_recos, df_test, on=['UserId'])\n",
    "print(df_eval.head(5))\n",
    "sum = 0\n",
    "for row in df_eval.itertuples(): # row[0] is the df index\n",
    "    if(row[13] in row[2:-1]):\n",
    "        sum +=1\n",
    "     \n",
    "print(\"Precision:\", sum/df_eval.shape[0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "%%bash\n",
    "\n",
    "cd /mnt/DataSets/MovieLens/ml-latest-small\n",
    "# Compute Precision@1-5 on out of time sample Test file with an external python script\n",
    "for k in 1 2 3 4 5; do\n",
    "    recPrecision_Arg.py -t lastItemPerUser.csv -p CF_cosine_ItemRecos.csv -k ${k}\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
